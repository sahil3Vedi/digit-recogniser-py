{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning on MNIST without Tensorflow",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahil3Vedi/digit-recogniser-py/blob/master/Deep_Learning_on_MNIST_without_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "44tpxiU1auZB",
        "colab_type": "code",
        "outputId": "47986f3e-8fd3-4a96-acde-87def550af14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#declaring all the dependencies NO KERAS OR TENSORFLOW\n",
        "\n",
        "import numpy as np\n",
        "import csv\n",
        "import math\n",
        "from google.colab import drive\n",
        "from math import e\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D0dOuVLGDRpF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Neural Network is Trained in 4 Stages:\n",
        "\n",
        "1) Network recieves input from model\n",
        "FUNCTION: NN.getInput(model.inputList)\n",
        "VARIABLES INVOLVED: NN.layers[0].inputVals\n",
        "\n",
        "2) Network activates one layer after the other.\n",
        "FUNCTION: NN.activate(activationFunction)\n",
        "VARIABLES INVOLVED: NN.layers[i].inputVals, NN.layers[i].activations, NN.layers[i].activDerivates, NN.layers[i].layerWeights, NN.layers[i].bias, NN.layers[i].biasWeights\n",
        "\n",
        "3) Model calculates cost from the target value of input data and answer provided by network.\n",
        "FUNCTION: model.getCost(NN)\n",
        "VARIABLES INVOLVED: NN.layers[-1].activations, NN.layers[-1].forwardError, model.cost\n",
        "\n",
        "4) Network readjusts the weights based on the cost and error information.\n",
        "FUNCTION: NN.backpropagate()\n",
        "VARIABLES INVOLVED: NN.layers[i].forwardError, NN.layers[i].diffWeights, NN.layers[i].diffBias, NN.layers[i-1].activations, NN.layers[i-1].forwardError"
      ]
    },
    {
      "metadata": {
        "id": "A8tGUPpNa_SB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class neuralNetwork:\n",
        "  layers=[]\n",
        "  finalError=[]\n",
        "  inputElem=0\n",
        "  hiddenElem=0\n",
        "  outputElem=0\n",
        "  \n",
        "  #When a neural network is declared \n",
        "  def __init__(self):\n",
        "    self.inputElem=784\n",
        "    self.outputElem=10\n",
        "    self.hiddenElem=20\n",
        "    \n",
        "    inputLayer = layer(self.inputElem,\"normalize\",None)\n",
        "    self.layers.append(inputLayer)\n",
        "    \n",
        "    temp = layer(self.hiddenElem,\"ReLU\",self.layers[0])\n",
        "    self.layers.append(temp)\n",
        "    temp = layer(self.hiddenElem,\"ReLU\",self.layers[1])\n",
        "    self.layers.append(temp)\n",
        "    temp = layer(self.hiddenElem,\"ReLU\",self.layers[2])\n",
        "    self.layers.append(temp)\n",
        "    \n",
        "    outputLayer = layer(self.outputElem,\"softMax\",self.layers[3])\n",
        "    self.layers.append(outputLayer)\n",
        "    #TOTAL 5 LAYERS\n",
        "    print(\"Neural Network Initialised...\")\n",
        "    \n",
        "  def getInput(self,i):\n",
        "    self.layers[0].inputVals=i\n",
        "    \n",
        "  def activate(self):\n",
        "    for i in range(0,len(self.layers)):\n",
        "      temp=self.layers[i].inputVals\n",
        "      activation=self.layers[i].activation\n",
        "      \n",
        "      if (activation==\"normalize\"):#typically used for the input layer. if you ask me it makes perfect sense to treat normalisation as input layer activation.\n",
        "        temp2=[(-1+(int(x)*2)/255) for x in temp]\n",
        "        temp3=None #this is because normalise is only being used on input layer where we dont need any back prop hence no need to calculate derivative.\n",
        "      \n",
        "      if (activation==\"ReLU\"):\n",
        "        temp2=[]\n",
        "        temp3=[]\n",
        "        for x in temp:\n",
        "          if (x>0):\n",
        "            y=x\n",
        "            temp3.append(1)\n",
        "          else:\n",
        "            y=0*x\n",
        "            temp3.append(0)\n",
        "          temp2.append(y)\n",
        "          \n",
        "      if (activation==\"tanH\"):\n",
        "        temp2=[]\n",
        "        temp3=[]\n",
        "        for x in temp:\n",
        "          a=e**(10*x)\n",
        "          b=e**(-10*x)\n",
        "          temp2.append((a-b)/(a+b))\n",
        "        for y in temp2:\n",
        "          temp3.append(y*(1-y))\n",
        "          \n",
        "      if (activation==\"softMax\"):\n",
        "        evec=[e**x for x in temp]\n",
        "        esum=np.sum(evec)\n",
        "        temp2=[y/esum for y in evec]\n",
        "        temp3=[q*(1-q) for q in temp2]\n",
        "        \n",
        "      self.layers[i].activations=temp2\n",
        "      self.layers[i].activDerivatives=temp3\n",
        "      \n",
        "      if(i!=len(self.layers)-1):#this is because we dont need to feed forward beyond the output layer.\n",
        "        self.layers[i].feedForward(self.layers[i+1])\n",
        "  \n",
        "  def backpropagate(self):\n",
        "    for i in range(len(self.layers)):\n",
        "      ind=-i-1\n",
        "      if(i!=len(self.layers)-1):\n",
        "        self.layers[ind].updateWeights(self.layers[ind-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JI26jhojzoG2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class model:\n",
        "  epoch=0\n",
        "  learningRate=0.1\n",
        "  cost=0\n",
        "  target=0\n",
        "  inputFile=[]\n",
        "  trainingEntries=0\n",
        "  accuracy=0\n",
        "  \n",
        "  def response(self,NN):\n",
        "    maxI=max(NN.layers[-1].activations)\n",
        "    indX=NN.layers[-1].activations.index(maxI)\n",
        "    if(str(self.target)==str(indX)):\n",
        "      self.accuracy+=1\n",
        "    self.epoch+=1\n",
        "    if(self.epoch%100==0):\n",
        "      print(\"Epoch: \" + str(self.epoch) + \" Cost: \" + str(self.cost) + \" Target: \" + str((self.target)) + \" Answer : \" + str(indX))\n",
        "      print(NN.layers[-3].activations)\n",
        "      print(\"Accuracy: \" + str(self.accuracy))\n",
        "      self.accuracy=0\n",
        "      \n",
        "  \n",
        "  def getInput(self,inputFile):\n",
        "    with open(inputFile) as csvFile:\n",
        "      csvReader = csv.reader(csvFile)\n",
        "      self.inputFile = list(csvReader)\n",
        "      self.trainingEntries = len(self.inputFile)-1  #n-1 because first row is header row\n",
        "      print(\"Total entries excluding header: \" + str(self.trainingEntries) + \" rows\")\n",
        "      \n",
        "  def getCost(self,NN):\n",
        "    targetVector=[]\n",
        "    for i in range(10):\n",
        "      if (str(i)==str(self.target)):\n",
        "        targetVector.append(1)\n",
        "      else:\n",
        "        targetVector.append(0)\n",
        "    output=NN.layers[-1].activations\n",
        "    error=[x-y for (x,y) in zip(output,targetVector)]\n",
        "    self.cost=0.5*(np.sum(np.square(error)))\n",
        "    NN.layers[-1].forwardError=error\n",
        "      \n",
        "  def trainNetwork(self,NN):\n",
        "    inputList=self.inputFile\n",
        "    inputList.pop(0)\n",
        "    for i in inputList:\n",
        "      self.target=i[0]\n",
        "      i.pop(0)\n",
        "      NN.getInput(i)\n",
        "      NN.activate()\n",
        "      self.getCost(NN)\n",
        "      NN.backpropagate()\n",
        "      Model.response(NN)\n",
        "      \n",
        "  def invCross(self,l1,l2): #this is the ONLY part that\n",
        "    temp=[]\n",
        "    for x in l1:\n",
        "      temptemp=[]\n",
        "      for y in l2:\n",
        "        temptemp.append(x*y)\n",
        "      temp.append(temptemp)\n",
        "    return temp\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aiSyxuUxdsDP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class layer:\n",
        "  numberElements=0\n",
        "  bias=0\n",
        "  activation=\"default\"\n",
        "  inputVals=[]\n",
        "  activations=[]\n",
        "  activDerivatives=[]\n",
        "  forwardError=[]\n",
        "  layerWeights=[]\n",
        "  biasWeights=[]\n",
        "  \n",
        "  #When a layer is declared\n",
        "  def __init__(self,no_of_elements,activation,previousLayer):\n",
        "    self.numberElements=no_of_elements\n",
        "    self.bias=0.0001\n",
        "    self.activation=activation\n",
        "    #Initialising the Weight Matrix\n",
        "    temp=[]\n",
        "    if(previousLayer!=None):\n",
        "      for i in range(previousLayer.numberElements):\n",
        "        temptemp=[]\n",
        "        for j in range(self.numberElements):\n",
        "          temptemp.append((np.random.random_sample()-0.5)*0.1)\n",
        "        temp.append(temptemp)\n",
        "    self.layerWeights=temp\n",
        "    #Initialising the Bias Matrix\n",
        "    self.biasWeights=[]\n",
        "    for i in range(self.numberElements):\n",
        "      self.biasWeights.append(np.random.random_sample()-0.5)\n",
        "      \n",
        "  def feedForward(self,nextLayer):\n",
        "    tempbias=self.bias\n",
        "    biasVec=nextLayer.biasWeights\n",
        "    temp2=np.matmul(self.activations,nextLayer.layerWeights)\n",
        "    temp3=np.multiply(tempbias,biasVec)\n",
        "    nextLayer.inputVals=[x+y for (x,y) in zip(temp2,temp3)]\n",
        "    \n",
        "  def updateWeights(self,prevLayer):\n",
        "    #declaring the Differential diagonal matrix\n",
        "    dmx=[]\n",
        "    for i in range(self.numberElements):\n",
        "      dtemp=[]\n",
        "      oi=self.activations[i]\n",
        "      for j in range(self.numberElements):\n",
        "        if(i==j):\n",
        "          dtemp.append(oi*(1-oi))\n",
        "        else:\n",
        "          dtemp.append(0)\n",
        "      dmx.append(dtemp)\n",
        "    #declaring do vector\n",
        "    dovec=np.matmul(dmx,self.forwardError)\n",
        "    wmx=Model.invCross(dovec,prevLayer.activations)\n",
        "    bvec=np.multiply((self.bias*Model.learningRate),dovec)\n",
        "    wMx=np.multiply(Model.learningRate,wmx)\n",
        "    tempW=np.subtract(self.layerWeights,np.transpose(wMx))\n",
        "    tempB=np.subtract(self.biasWeights,bvec)\n",
        "    self.layerWeights=tempW\n",
        "    prevLayer.forwardError=np.matmul(self.layerWeights,dovec)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GihhafanX14r",
        "colab_type": "code",
        "outputId": "29b3dabb-3236-494b-eecd-f850e185a1be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3312
        }
      },
      "cell_type": "code",
      "source": [
        "#-----MAIN FUNCTION-----\n",
        "\n",
        "Model = model()\n",
        "inputFile='drive/My Drive/MNIST Image CSV/train.csv'\n",
        "Model.getInput(inputFile)\n",
        "\n",
        "NN = neuralNetwork()\n",
        "Model.trainNetwork(NN)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total entries excluding header: 42000 rows\n",
            "Neural Network Initialised...\n",
            "Epoch: 100 Cost: 0.45003623663700487 Target: 5 Answer : 4\n",
            "[-0.0, 0.022938254112737574, 0.018406522842450927, 0.05409498385910726, 0.11640706751134423, -0.0, 0.035315108007558056, -0.0, 0.11201480672058207, -0.0, 0.0831895182959134, -0.0, 0.031908906602126044, 0.025320149723813662, 0.06831142121053524, 0.09096586394671975, 0.025549912281538804, -0.0, 0.05079604872545726, -0.0]\n",
            "Accuracy: 6\n",
            "Epoch: 200 Cost: 0.4500621926641234 Target: 2 Answer : 4\n",
            "[0.009006050548194538, -0.0, 0.06785340051246115, 0.06957050053085974, 0.15686981029698613, -0.0, 0.09112012323233983, -0.0, 0.11781749347641932, -0.0, 0.02083287358675099, 0.0398279805369658, 0.06634767985622157, -0.0, 0.09036335549313661, 0.06069586233576264, -0.0, -0.0, 0.028749423356840657, -0.0]\n",
            "Accuracy: 11\n",
            "Epoch: 300 Cost: 0.44980064056897623 Target: 4 Answer : 4\n",
            "[-0.0, 0.028260697435033327, 0.03556555000830277, 0.12491769232027587, 0.11754282014227456, -0.0, 0.08057690727857138, 0.0849606878189519, 0.08189865844672485, -0.0, -0.0, 0.12253651589046524, 0.08016131277459773, -0.0, 0.09093973670762513, 0.11411362626932102, 0.020164022557020315, -0.0, -0.0, -0.0]\n",
            "Accuracy: 14\n",
            "Epoch: 400 Cost: 0.4501088621063736 Target: 6 Answer : 4\n",
            "[-0.0, -0.0, 0.044597069870561404, 0.10034763274431835, 0.134427569514547, -0.0, 0.015772375950601276, -0.0, 0.06917491515420846, -0.0, -0.0, 0.06230702028143881, 0.012940064628656087, 0.0039494651854351664, 0.10350457539319444, 0.09838570700701524, -0.0, -0.0, 0.02076518156552609, -0.0]\n",
            "Accuracy: 15\n",
            "Epoch: 500 Cost: 0.45007995130252715 Target: 9 Answer : 4\n",
            "[-0.0, -0.0, -0.0, 0.12342437566696515, 0.11885172309504624, -0.0, 0.08654659390176107, 0.0613179448205573, 0.2016783926350391, -0.0, 0.04033907632709025, 0.09375435170863877, 0.09827695045034147, -0.0, 0.09593606875964514, 0.08866354567921521, 0.008989681193162218, -0.0, -0.0, -0.0]\n",
            "Accuracy: 9\n",
            "Epoch: 600 Cost: 0.4500183165834485 Target: 2 Answer : 4\n",
            "[0.016032129859246673, -0.0, 0.07428181960087842, 0.08172825762774645, 0.10743360279160659, -0.0, 0.06328713513127522, 0.008509693421853577, 0.12380410453393766, -0.0, 0.045738184200612014, 0.016653763765885198, 0.08335896971063497, -0.0, 0.05386870072243785, 0.06787597926727806, 0.017119100986301004, -0.0, 0.03879654733480974, -0.0]\n",
            "Accuracy: 13\n",
            "Epoch: 700 Cost: 0.4501188067287069 Target: 6 Answer : 4\n",
            "[-0.0, -0.0, 0.05733862480161619, 0.0737076938273304, 0.1176346510422509, 0.014338491472243451, 0.03679223459290325, -0.0, 0.08759584050798172, -0.0, 0.021539214658159833, 0.027023131049219953, 0.014741820312239008, 0.023597303568115263, 0.10397714908288823, 0.08951825873717485, -0.0, -0.0, 0.0440155927867152, -0.0]\n",
            "Accuracy: 17\n",
            "Epoch: 800 Cost: 0.4500915653203761 Target: 9 Answer : 7\n",
            "[-0.0, -0.0, 0.08178676645964317, 0.04329381060233617, 0.12923140181483203, -0.0, 0.0884299280287123, 0.02000805141869145, 0.101581405814003, -0.0, 0.13212749728511158, 0.06898453373523929, -0.0, -0.0, 0.10642434279498397, 0.06867911750886721, 0.04744483758343422, -0.0, 0.027979455042130473, -0.0]\n",
            "Accuracy: 8\n",
            "Epoch: 900 Cost: 0.44984765241703595 Target: 4 Answer : 4\n",
            "[0.04448664616080207, -0.0, 0.06900121414207733, 0.08689915967118608, 0.1258759355027312, -0.0, 0.02614073180190622, 0.009932274092840409, 0.0650547292774912, -0.0, -0.0, 0.09635685596213232, 0.025258667328930496, 0.007258633416872138, 0.0985247314531441, 0.10786651595099318, -0.0, -0.0, 0.011841767748115002, -0.0]\n",
            "Accuracy: 16\n",
            "Epoch: 1000 Cost: 0.4498332791112833 Target: 4 Answer : 4\n",
            "[0.005302262530317532, 0.015667847305403968, 0.04798177698278976, 0.10600339320599617, 0.12270690542414038, -0.0, 0.07050327524597716, 0.04398508987364061, 0.0831817690332561, -0.0, 0.016855244775665412, 0.10457838504858102, 0.03020252573086759, -0.0, 0.07157516945645696, 0.08146756099224788, 0.015844861398448717, -0.0, 0.010170513633718003, -0.0]\n",
            "Accuracy: 17\n",
            "Epoch: 1100 Cost: 0.4498784839685763 Target: 4 Answer : 7\n",
            "[0.0915516868944784, -0.0, 0.09519029556805034, 0.0553298540015335, 0.08882068760258223, -0.0, 0.08678943990661264, 0.05447963988202015, 0.09280726679205054, -0.0, 0.06336780929305778, 0.11407357484915932, 0.006731296927444692, -0.0, 0.11626081865524229, 0.10132040862798579, 0.005030236129575381, -0.0, 0.029483969524077995, -0.0]\n",
            "Accuracy: 10\n",
            "Epoch: 1200 Cost: 0.449966140449639 Target: 5 Answer : 4\n",
            "[0.005174072209654328, 0.04263871944916047, 0.1367344370299138, 0.11204679478574585, 0.15037695510803997, -0.0, 0.01288771626756122, 0.018117619916257186, 0.055384496284710504, -0.0, -0.0, 0.056971058690469666, 0.031036925765371832, -0.0, 0.1076766417078018, 0.09841457740059285, -0.0, -0.0, 0.013731781311264445, -0.0]\n",
            "Accuracy: 12\n",
            "Epoch: 1300 Cost: 0.4501539236821196 Target: 8 Answer : 7\n",
            "[-0.0, -0.0, 0.09125903327833602, 0.006474801227601523, 0.12148742443121814, -0.0, 0.02472383520519742, -0.0, 0.04018737304611415, -0.0, 0.005355216149213044, 0.08519701406628961, -0.0, -0.0, 0.14834918947724812, 0.03120899539215904, -0.0, -0.0, 0.03409687575343781, -0.0]\n",
            "Accuracy: 10\n",
            "Epoch: 1400 Cost: 0.45004936535334134 Target: 6 Answer : 7\n",
            "[0.06571677461234769, 0.024123126099091115, 0.1058377983635778, 0.0444139174158788, 0.13006317587910748, -0.0, 0.0401897406874741, -0.0, 0.031957044804008655, -0.0, 0.05111126476344506, 0.020675076474355115, 0.033604626604185076, -0.0, 0.10208297531177782, 0.11185300205951769, -0.0, -0.0, 0.007991807312238803, -0.0]\n",
            "Accuracy: 12\n",
            "Epoch: 1500 Cost: 0.45005338202806183 Target: 2 Answer : 4\n",
            "[-0.0, -0.0, 0.051365873347468546, 0.06894730878461808, 0.16638425354252484, -0.0, 0.0710292850063104, -0.0, 0.06936332752840434, -0.0, 0.03357378721691083, 0.10085896485158961, -0.0, -0.0, 0.11049128304682804, 0.05565362596819478, 0.01027013503773981, -0.0, 0.038707451617582586, -0.0]\n",
            "Accuracy: 9\n",
            "Epoch: 1600 Cost: 0.4501061431461567 Target: 9 Answer : 4\n",
            "[0.01105863755374893, -0.0, 0.08619998916261713, 0.06714032571697649, 0.14447486063250695, -0.0, 0.09836342269402161, 0.018047119323983007, 0.10104228297363231, -0.0, 0.010311317582937612, 0.09969525325112753, 0.03427727482149474, -0.0, 0.08498797797672396, 0.0808327022699266, 0.013087189995685332, -0.0, 0.0300115354104122, -0.0]\n",
            "Accuracy: 10\n",
            "Epoch: 1700 Cost: 0.4498398041366166 Target: 4 Answer : 4\n",
            "[0.015155834604255137, -0.0, 0.05872428734523768, 0.07315524087774238, 0.12494335219083987, -0.0, 0.061434546103620064, 0.019212845348732147, 0.1153743206099533, -0.0, 0.032056728451355376, 0.11474640136071099, 0.004038213901947179, -0.0, 0.08028340916625584, 0.06868965674431582, -0.0, -0.0, 0.022913118260012376, -0.0]\n",
            "Accuracy: 10\n",
            "Epoch: 1800 Cost: 0.4501685350057006 Target: 8 Answer : 7\n",
            "[0.00423538053952018, 0.006327044184958211, 0.12575377364418064, 0.04633719042538308, 0.11510390201444544, -0.0, 0.05361666918990978, 0.03682498166957743, 0.0608793933627878, -0.0, 0.09749009051256263, 0.03271362384462775, 0.0632820343777532, -0.0, 0.08970173128587978, 0.09921990978362401, 0.005168629873086707, -0.0, -0.0, -0.0]\n",
            "Accuracy: 11\n",
            "Epoch: 1900 Cost: 0.4500458317468337 Target: 1 Answer : 4\n",
            "[0.007323047765376689, -0.0, 0.03521053250875053, 0.07820811638776891, 0.1687322064488332, -0.0, 0.04084163059485983, -0.0, 0.06288225933561843, -0.0, -0.0, 0.10870754204803026, -0.0, 0.02105750154722234, 0.14224606545743512, 0.10739722421184615, -0.0, -0.0, 0.05115813573938299, -0.0]\n",
            "Accuracy: 13\n",
            "Epoch: 2000 Cost: 0.4498770991855548 Target: 4 Answer : 7\n",
            "[0.019522905588578787, -0.0, 0.14457490861521147, 0.02105011893450877, 0.11563340139207072, -0.0, 0.14304579249414143, 0.05774771661496495, 0.04499971789188579, -0.0, 0.08137542794209794, 0.13530652795594117, 0.04702998018301197, -0.0, 0.11481740469842934, 0.06659467854791615, 0.004981475303515402, 0.007331305656689205, -0.0, -0.0]\n",
            "Accuracy: 10\n",
            "Epoch: 2100 Cost: 0.45000761227391267 Target: 1 Answer : 4\n",
            "[-0.0, 0.015072903274340589, 0.014191734717667305, 0.08510263953734905, 0.13790641802002812, -0.0, 0.00935216126618414, -0.0, 0.03862932206372132, -0.0, -0.0, 0.061883626893487316, -0.0, 0.024981007339968324, 0.12405871950587813, 0.09677425306514434, -0.0, -0.0, 0.027910906881945217, -0.0]\n",
            "Accuracy: 9\n",
            "Epoch: 2200 Cost: 0.45017614454093235 Target: 8 Answer : 7\n",
            "[0.003921948338161303, 0.026156622832511866, 0.1370563224812275, 0.0752362999365311, 0.11035085064307541, -0.0, -0.0, 0.024277426579370737, 0.05512068592941142, -0.0, 0.08811061038985611, 0.003763027474218185, 0.048325486823369526, -0.0, 0.10896930213108964, 0.13339029966240093, -0.0, -0.0, -0.0, -0.0]\n",
            "Accuracy: 10\n",
            "Epoch: 2300 Cost: 0.45005938294522296 Target: 6 Answer : 4\n",
            "[-0.0, 0.023671041732060413, 0.010299437198361083, 0.10305860100692385, 0.10726134974682752, -0.0, -0.0, -0.0, 0.03739257287329104, -0.0, -0.0, 0.029578581102906, 0.017775032419384548, -0.0, 0.09642775118575887, 0.059639003927524144, -0.0, -0.0, 0.002464801670259564, -0.0]\n",
            "Accuracy: 10\n",
            "Epoch: 2400 Cost: 0.4498621596493448 Target: 4 Answer : 4\n",
            "[0.029131875915654932, -0.0, 0.025860506369283585, 0.08472711794541916, 0.08712532759199591, -0.0, 0.06407161492736328, 0.07309522773274757, 0.08589874663257692, -0.0, 0.06950141217974508, 0.16327396454377988, 0.0280426107308385, -0.0, 0.062290317604948485, 0.07347646700449867, -0.0, -0.0, -0.0, -0.0]\n",
            "Accuracy: 6\n",
            "Epoch: 2500 Cost: 0.45020900347043336 Target: 8 Answer : 7\n",
            "[-0.0, -0.0, 0.06496633406291502, 0.039150581422128246, 0.14169327458444902, -0.0, 0.08984880190923722, 0.007132760486280773, 0.06857672243486677, -0.0, 0.06351822615150976, 0.12344118608472641, -0.0, -0.0, 0.13642935233976877, 0.08950700665425869, 0.00962913699399878, -0.0, 0.022073892765711742, -0.0]\n",
            "Accuracy: 15\n",
            "Epoch: 2600 Cost: 0.45002394841495535 Target: 1 Answer : 4\n",
            "[0.01040783594638345, -0.0, 0.008119162974805093, 0.06885696845069156, 0.1439862935923805, -0.0, 0.04336832435741204, -0.0, 0.05634668805077249, -0.0, -0.0, 0.11127891812753439, -0.0, 0.012542005628112946, 0.1073897801067207, 0.0730035758465527, -0.0, -0.0, 0.04318885097181033, -0.0]\n",
            "Accuracy: 12\n",
            "Epoch: 2700 Cost: 0.44994068359509615 Target: 5 Answer : 7\n",
            "[0.0012187451398281539, 0.002097204455730353, 0.18236810890138716, 0.05443280371738195, 0.18669970279544618, -0.0, 0.0945057100455235, -0.0, 0.02870730815493338, -0.0, 0.01885682589859696, 0.035140375208394005, 0.014958293799768024, -0.0, 0.13288635483332592, 0.0755026300891155, 0.022228366220108094, -0.0, 0.05048890075330431, -0.0]\n",
            "Accuracy: 18\n",
            "Epoch: 2800 Cost: 0.449800062755602 Target: 7 Answer : 7\n",
            "[0.057715020404729374, -0.0, 0.20850131003875091, -0.0, 0.07141827135927206, -0.0, 0.1494046855595637, 0.024927533528578755, 0.04133499899681057, -0.0, 0.034350995278645526, 0.07346138181197724, 0.0066052006401029865, -0.0, 0.1296857612203065, 0.07367964455595769, 0.02116737326316856, -0.0, 0.043748948769629786, -0.0]\n",
            "Accuracy: 10\n",
            "Epoch: 2900 Cost: 0.44990341348741275 Target: 0 Answer : 4\n",
            "[0.031554210748058045, -0.0, 0.01797647842611069, 0.026990105502433095, 0.04648615033993417, -0.0, 0.03834263937628959, 0.028123358095167132, 0.12493025747232506, -0.0, 0.014561906096221768, 0.10382452920463421, -0.0, 0.06849831425416472, 0.09042569290439582, 0.0808888861625471, -0.0, -0.0, 0.02812899019475988, -0.0]\n",
            "Accuracy: 13\n",
            "Epoch: 3000 Cost: 0.44996235107112564 Target: 3 Answer : 7\n",
            "[-0.0, -0.0, 0.07049160946937325, 0.0028482143093610736, 0.16725629691608246, 0.021457321293917198, 0.0869215236974657, -0.0, 0.003117955769096819, -0.0, 0.0021660755647878917, 0.07434554807922045, -0.0, -0.0, 0.14039594071918843, -0.0, -0.0, 0.029306651108366, 0.021968341839642108, -0.0]\n",
            "Accuracy: 11\n",
            "Epoch: 3100 Cost: 0.4499265545810674 Target: 0 Answer : 7\n",
            "[-0.0, -0.0, 0.15824564846656525, 0.034331826309815544, 0.14869341751105533, -0.0, 0.11315549322547278, -0.0, 0.04277821998278016, -0.0, 0.0012444785271764694, 0.0489737566494464, 0.03598268094170435, -0.0, 0.11689085716385884, 0.034963491540561956, 0.025243808182634858, 0.021036671857110615, 0.040172889192521, -0.0]\n",
            "Accuracy: 8\n",
            "Epoch: 3200 Cost: 0.44993430006549917 Target: 0 Answer : 4\n",
            "[-0.0, -0.0, 0.08758278717100183, 0.04357088238555529, 0.09062695094615557, -0.0, 0.037898830777170975, 0.0028331300359015306, 0.09686723225342635, -0.0, -0.0, 0.042511265930326315, 0.023987974116141474, -0.0, 0.08235549355278925, 0.04728234731873189, 0.017171757849772692, -0.0, 0.037534597504823256, -0.0]\n",
            "Accuracy: 8\n",
            "Epoch: 3300 Cost: 0.4499203567885272 Target: 0 Answer : 4\n",
            "[0.01711305888514031, -0.0, 0.035642020261159306, 0.02671890470133961, 0.009082053906853434, -0.0, 0.05560095328247449, 0.06114483934538681, 0.16594428898865618, -0.0, 0.03243143744775456, 0.08569728867163384, 0.0029613953227673948, 0.008330874088741025, 0.028435091283367957, 0.01440127897389945, 0.02590930820301516, -0.0, 0.04216211162627723, -0.0]\n",
            "Accuracy: 13\n",
            "Epoch: 3400 Cost: 0.45015041398162725 Target: 8 Answer : 7\n",
            "[0.059998961356533945, 0.04304427933871133, 0.08914600375858683, 0.08251520453123393, 0.05583784976169957, -0.0, -0.0, 0.04768012271033271, 0.03342592502002991, -0.0, 0.04711096269616022, 0.04200914678274808, 0.005703343440976085, 0.03286400258710486, 0.08488819928571165, 0.12027721790208654, -0.0, -0.0, -0.0, -0.0]\n",
            "Accuracy: 11\n",
            "Epoch: 3500 Cost: 0.45001344464325543 Target: 1 Answer : 4\n",
            "[0.0016678314975064796, -0.0, -0.0, 0.06136679319387443, 0.14067409293331104, -0.0, 0.041395989195707805, -0.0, 0.048240364487355775, -0.0, -0.0, 0.08813557288985009, -0.0, 0.02040263462725624, 0.11169719613271041, 0.0797304114873013, -0.0, -0.0, 0.04314271140950219, -0.0]\n",
            "Accuracy: 10\n",
            "Epoch: 3600 Cost: 0.4499213702174673 Target: 0 Answer : 4\n",
            "[0.03603466143257931, 0.029947446427473365, 0.08576433840535551, 0.07327446932353614, 0.10104924874601766, -0.0, 0.02008628859746201, 0.019687024219565474, 0.07747969354402044, -0.0, -0.0, 0.053295215174543005, 0.00571416191165524, -0.0, 0.10042313041685755, 0.10517444065931383, 0.005584933915239476, -0.0, 0.041060477103549764, -0.0]\n",
            "Accuracy: 12\n",
            "Epoch: 3700 Cost: 0.4499271890652384 Target: 0 Answer : 7\n",
            "[0.01927267676172263, -0.0, 0.0596211587651191, 0.03613712706802541, 0.04703529628147125, -0.0, -0.0, 0.033115264694687466, 0.044162504392712104, -0.0, 0.046525978719119204, 0.05754085809778755, 0.0012376698613886044, 0.04074633290462435, 0.08969450958873666, 0.09394107906028781, -0.0, -0.0, -0.0, -0.0]\n",
            "Accuracy: 9\n",
            "Epoch: 3800 Cost: 0.4499850717135372 Target: 5 Answer : 4\n",
            "[0.01581988824196755, 0.028639040157209073, 0.04681934252040391, 0.12155030386838475, 0.14338007648323237, -0.0, 0.055693061587067154, 0.044135251515150735, 0.08490905854444425, -0.0, 0.029481822486304557, 0.10829730126241233, 0.022533232511069107, -0.0, 0.08332655312845454, 0.1072355097324691, 0.008898973603841405, -0.0, 0.004214981812141425, -0.0]\n",
            "Accuracy: 21\n",
            "Epoch: 3900 Cost: 0.45008304597430016 Target: 6 Answer : 4\n",
            "[-0.0, 0.030155195091938407, 0.049486328350799615, 0.11509366302587862, 0.12569141565475922, -0.0, 0.0003352284928024273, 0.012531428436347596, 0.032522308458756054, -0.0, -0.0, 0.0674440198880031, 0.03096942290416439, -0.0, 0.07910640498681926, 0.06946076850498857, -0.0, -0.0, -0.0, -0.0]\n",
            "Accuracy: 13\n",
            "Epoch: 4000 Cost: 0.44989966764060924 Target: 4 Answer : 7\n",
            "[0.0668812113121131, 0.021124186220720948, 0.07869965321453001, 0.08245855571853243, 0.15047446170813397, -0.0, 0.043778404691292135, -0.0, 0.06993305172279761, -0.0, 0.09665072212969492, 0.035309035275418475, 0.010525566267359173, -0.0, 0.09591398110487412, 0.0963626140915262, -0.0, -0.0, 0.028983840743766344, -0.0]\n",
            "Accuracy: 10\n",
            "Epoch: 4100 Cost: 0.450225481706873 Target: 8 Answer : 7\n",
            "[-0.0, -0.0, 0.13118575158769352, 0.04829648027006785, 0.17003476557103844, -0.0, 0.0658669010689667, -0.0, 0.04713530381068978, -0.0, -0.0, 0.08928483003529768, 0.0029293309439391044, -0.0, 0.1363542323093957, 0.08982674163695438, -0.0, -0.0, 0.021383530027439132, -0.0]\n",
            "Accuracy: 9\n",
            "Epoch: 4200 Cost: 0.44999743283636545 Target: 5 Answer : 7\n",
            "[0.10634884712453756, -0.0, 0.1611791613273019, 0.020680988531799636, 0.13065060898262668, -0.0, 0.05066611745290816, -0.0, 0.0979489148505226, -0.0, 0.01301711632185586, 0.008498280682234228, 0.06201905853585524, 0.0033783614632325425, 0.09152604736275227, 0.1417345515922902, -0.0, -0.0, 0.04677499437128567, -0.0]\n",
            "Accuracy: 12\n",
            "Epoch: 4300 Cost: 0.45007956425321766 Target: 6 Answer : 7\n",
            "[0.10699802030276741, 0.04188473588910377, 0.12266346628448127, 0.06632971093180638, 0.08220096725619537, -0.0, -0.0, 0.01503660753753776, 0.06256172542670847, -0.0, -0.0, 0.051940318412883595, 0.03967519884622656, -0.0, 0.10030296059838684, 0.08594546897569562, -0.0, -0.0, 0.029645126673925683, -0.0]\n",
            "Accuracy: 9\n",
            "Epoch: 4400 Cost: 0.44986696961619144 Target: 4 Answer : 7\n",
            "[-0.0, -0.0, 0.15275664573811606, 0.04883593559890942, 0.1413014867596214, -0.0, 0.08317414063479113, 0.03273744784181835, 0.0679207480109626, -0.0, 0.08599550948605227, 0.08422468707177101, 0.029226657704064112, -0.0, 0.1273604123252332, 0.09986815061816604, 0.01520055801916, -0.0, 0.003488784787222624, -0.0]\n",
            "Accuracy: 5\n",
            "Epoch: 4500 Cost: 0.44988816401269227 Target: 4 Answer : 7\n",
            "[-0.0, -0.0, 0.05593423519431275, 0.07048000560277089, 0.1416544248675985, -0.0, 0.03860852654554723, -0.0, 0.03280696430622771, -0.0, 0.011893164835267374, 0.06782708838457385, 0.013125318381847495, -0.0, 0.10662771923883282, 0.06081689244064138, -0.0, -0.0, -0.0, -0.0]\n",
            "Accuracy: 12\n",
            "Epoch: 4600 Cost: 0.4498983511608485 Target: 4 Answer : 7\n",
            "[0.04467962770508093, -0.0, 0.09330380498054594, 0.05411270072635163, 0.14961501754099707, -0.0, 0.06226937989777873, -0.0, 0.09720702715855546, -0.0, 0.13452023655939505, 0.07405038948700421, 0.013224431152191237, 0.008502059488775486, 0.14776911704135298, 0.12317895419875281, -0.0, -0.0, 0.022663711477620956, -0.0]\n",
            "Accuracy: 17\n",
            "Epoch: 4700 Cost: 0.45008257516525946 Target: 9 Answer : 7\n",
            "[0.010637671395620453, 0.01815052031825624, 0.09449157416135712, 0.08478576657555455, 0.1494810053623984, -0.0, 0.0500465562851704, 0.011256592398064773, 0.03905346435546526, -0.0, 0.00628285528134756, 0.0772701318569193, 0.004104858115408661, -0.0, 0.10194082027979683, 0.09595163569941052, 0.004054648529478321, -0.0, 0.016320557085565394, -0.0]\n",
            "Accuracy: 7\n",
            "Epoch: 4800 Cost: 0.45022705293077514 Target: 8 Answer : 7\n",
            "[-0.0, 0.038319608983413966, 0.04633739963880155, 0.13651339600078174, 0.10020359066358173, -0.0, -0.0, 0.052590916367342554, 0.0676130472272754, -0.0, 0.08345148894548735, 0.049760403887975514, 0.04846258934575925, 0.020036881607421304, 0.11192154414851403, 0.13972257742832722, -0.0, -0.0, -0.0, -0.0]\n",
            "Accuracy: 8\n",
            "Epoch: 4900 Cost: 0.450054861943493 Target: 1 Answer : 7\n",
            "[0.004406041381128299, 0.0014780419637226616, 0.05767967478676036, 0.05287349251470036, 0.13739059552198524, -0.0, 0.064118236779451, 0.0008082096830924633, 0.054374744053196096, -0.0, 0.062327378362314716, 0.07587951051212935, -0.0, -0.0, 0.11107152646648652, 0.10053069998581572, 0.01454148247117738, -0.0, 0.034117878412560906, -0.0]\n",
            "Accuracy: 11\n",
            "Epoch: 5000 Cost: 0.4500487796112749 Target: 9 Answer : 7\n",
            "[0.06569012854351575, 0.01683152048966594, 0.10718799792202817, 0.11527993222021721, 0.19151670991821054, -0.0, -0.0, -0.0, 0.026478757408314443, -0.0, -0.0, 0.0630442525045775, -0.0, 0.027614958120908004, 0.17581272901812137, 0.14867752654826605, -0.0, -0.0, 0.014744667314643812, -0.0]\n",
            "Accuracy: 15\n",
            "Epoch: 5100 Cost: 0.45001807619419226 Target: 9 Answer : 7\n",
            "[0.04747118878774433, 0.004090761693401569, 0.09892919619721809, 0.0773088483944209, 0.12679394064054755, -0.0, 0.008439779459942624, 0.028855228375811115, 0.059678809748922784, -0.0, 0.05005699067616979, 0.0846315262993725, 0.008841973634453857, -0.0, 0.11250062676739966, 0.13196885197770233, -0.0, -0.0, -0.0, -0.0]\n",
            "Accuracy: 13\n",
            "Epoch: 5200 Cost: 0.450026682296162 Target: 1 Answer : 7\n",
            "[0.01082688880465066, -0.0, 0.06797391350657409, 0.05139320773526007, 0.12888959088498084, -0.0, 0.04087109726082273, -0.0, 0.0312716661692461, -0.0, 0.010404383974541104, 0.07267344320068955, -0.0, -0.0, 0.10306037593476408, 0.08213163209218975, -0.0, -0.0, 0.027507397673190184, -0.0]\n",
            "Accuracy: 12\n",
            "Epoch: 5300 Cost: 0.44993805850134005 Target: 0 Answer : 7\n",
            "[-0.0, -0.0, 0.02509444636534076, 0.02489442791531591, 0.16579762242589072, -0.0, 0.14129317531422816, -0.0, 0.07046767254150817, -0.0, 0.06220573062531684, 0.08589709522970959, -0.0, -0.0, 0.14005714516216783, 0.041162284808849633, 0.03854862032574956, 0.03693761106284983, 0.0574685423650497, -0.0]\n",
            "Accuracy: 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-5f31015f62da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-89-d1bec60e8761>\u001b[0m in \u001b[0;36mtrainNetwork\u001b[0;34m(self, NN)\u001b[0m\n\u001b[1;32m     47\u001b[0m       \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m       \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-88-b367df7cbfac>\u001b[0m in \u001b[0;36mactivate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#this is because we dont need to feed forward beyond the output layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedForward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbackpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-90-a626bb878000>\u001b[0m in \u001b[0;36mfeedForward\u001b[0;34m(self, nextLayer)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtempbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mbiasVec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnextLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiasWeights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mtemp2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnextLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayerWeights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mtemp3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtempbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbiasVec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mnextLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputVals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}